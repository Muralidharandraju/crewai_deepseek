{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting PyPDF2\n",
      "  Downloading pypdf2-3.0.1-py3-none-any.whl.metadata (6.8 kB)\n",
      "Downloading pypdf2-3.0.1-py3-none-any.whl (232 kB)\n",
      "Installing collected packages: PyPDF2\n",
      "Successfully installed PyPDF2-3.0.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install PyPDF2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from config import configure\n",
    "import os\n",
    "from langchain_community.document_loaders import PyMuPDFLoader\n",
    "from pydantic import BaseModel, Field\n",
    "from model.topic_content import Topicsummary\n",
    "from crewai import Agent,Crew,Process,Task,LLM\n",
    "from crewai.project import agent,crew,task,CrewBase\n",
    "from langchain_ollama import OllamaLLM\n",
    "import logging\n",
    "import PyPDF2 as pdf\n",
    "# from langchain_openai import ChatOpenAI\n",
    "from langchain_community.chat_models.openai import ChatOpenAI\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm_model=LLM(model=\"ollama/deepseek-r1:7b\", base_url=\"http://127.0.0.1:11434\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "temp_dir = 'temp/'\n",
    "logging = 'temp/logging/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class Topicsummary(BaseModel):\n",
    "    topic: str = Field(..., description=\"The topics that discussed in the pdf or given text\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_model = OllamaLLM(model=\"crewai-deepseek-r1\",api_key=\"NA\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pdf_to_text(pdf_path):\n",
    "    # Open the PDF file in read-binary mode\n",
    "    with open(pdf_path, 'rb') as pdf_file:\n",
    "        # Create a PdfReader object instead of PdfFileReader\n",
    "        pdf_reader = pdf.PdfReader(pdf_file)\n",
    "\n",
    "        # Initialize an empty string to store the text\n",
    "        text = ''\n",
    "\n",
    "        for page_num in range(len(pdf_reader.pages)):\n",
    "            page = pdf_reader.pages[page_num]\n",
    "            text += page.extract_text()\n",
    "\n",
    "    # Write the extracted text to a text file\n",
    "    # with open('/crewai_deepseek/temp/output.txt', 'w', encoding='utf-8') as txt_file:\n",
    "    #     txt_file.write(text)\n",
    "    return text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = pdf_to_text(\"/crewai_deepseek/temp/glue-dg.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Agent 1: Concept Definition Agent\n",
    "concept_definition_agent = Agent(\n",
    "    role=\"Concept Definition Agent\",\n",
    "    goal=\"To create comprehensive data dictionaries, metadata repositories, and data governance documentation, ensuring data consistency and quality.\"\n",
    "    \"To help users understand the structure and usage of data within a system or document, enabling accurate data management, analysis, and reporting.\",\n",
    "    verbose=True,\n",
    "    backstory=(\n",
    "        \"Developed to assist in data governance, data modeling, and data warehousing projects.\"\n",
    "        \"Initially used for creating glossaries and educational content, it has been refined to provide in-depth conceptual explanations for diverse fields.\"\n",
    "        \"you are in the creation of educational materials, technical documentation, and knowledge bases.\"\n",
    "    ),llm=llm_model\n",
    "\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Task for Researcher Agent: Extract definitions\n",
    "concept_definition_task = Task(\n",
    "    description=(\n",
    "        \"Identify and define all key concepts presented in the document.\" \n",
    "        \"For each concept, provide a detailed definition along with contextual examples or use cases that illustrate its application.\" \n",
    "        \"Present each concept in the format: 'Concept Name: Detailed Definition with Contextual Examples'.\"\n",
    "    ),\n",
    "    expected_output=(\n",
    "        \"A list of key concepts, with each concept accompanied by a detailed definition and contextual examples or use cases.\"\n",
    "    ),\n",
    "    agent=concept_definition_agent,\n",
    "    async_execution=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:opentelemetry.trace:Overriding of current TracerProvider is not allowed\n"
     ]
    }
   ],
   "source": [
    "definition_extract_crew = Crew(agents=[concept_definition_agent],\n",
    "     tasks=[concept_definition_task])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mConcept Definition Agent\u001b[00m\n",
      "\u001b[95m## Task:\u001b[00m \u001b[92mIdentify and define all key concepts presented in the document.For each concept, provide a detailed definition along with contextual examples or use cases that illustrate its application.Present each concept in the format: 'Concept Name: Detailed Definition with Contextual Examples'.\u001b[00m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ðŸ–‡ AgentOps: Could not end session - no sessions detected\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m\u001b[95m# Agent:\u001b[00m \u001b[1m\u001b[92mConcept Definition Agent\u001b[00m\n",
      "\u001b[95m## Final Answer:\u001b[00m \u001b[92m\n",
      "1. **Data Governance Framework**  \n",
      "   - **Definition**: A structured approach to managing data policies, standards, and processes within an organization to ensure compliance, consistency, and quality of data assets.  \n",
      "   - **Contextual Example**: Organizations like XYZ utilize Data Governance Frameworks to implement data quality policies that prevent errors and ensure data usability across departments.\n",
      "\n",
      "2. **Data Quality Scorecard**  \n",
      "   - **Definition**: A tool used to monitor and evaluate the quality of data within an organization, often presented as a score or rating based on predefined metrics.  \n",
      "   - **Contextual Example**: Companies use Data Quality Scorecards to track metrics like completeness, accuracy, and consistency, helping them identify areas for improvement.\n",
      "\n",
      "3. **Metadata Schema**  \n",
      "   - **Definition**: A comprehensive document describing the structure of metadata within an organization, detailing data elements, relationships, and access controls.  \n",
      "   - **Contextual Example**: In healthcare, Metadata Schemas are used to manage patient records, ensuring that information is standardized and easily accessible by different systems.\n",
      "\n",
      "4. **Data Warehouse Schema Design**  \n",
      "   - **Definition**: The process of designing the structure of a Data Warehouse, including tables, columns, relationships, and constraints to organize data effectively.  \n",
      "   - **Contextual Example**: A retail company might design its Data Warehouse Schema to store sales transactions, inventory levels, and customer demographics for efficient reporting.\n",
      "\n",
      "5. **Extract, Transform, Load (ETL) Process**  \n",
      "   - **Definition**: A process used in data warehousing to extract data from various sources, transform it into a usable format, and load it into the target system.  \n",
      "   - **Contextual Example**: An e-commerce platform uses ETL processes to aggregate sales data from different databases, clean the data, and load it into its Data Warehouse for analytics.\n",
      "\n",
      "6. **Data Mart**  \n",
      "   - **Definition**: A subset of a Data Warehouse that focuses on specific business functions or departments, providing tailored data for operational needs.  \n",
      "   - **Contextual Example**: A university's Academic Data Mart aggregates student records, course information, and research data to support academic reporting and planning.\n",
      "\n",
      "7. **Data Validation Rules**  \n",
      "   - **Definition**: Predefined rules used to ensure the integrity of data during entry or processing, flagging invalid or incomplete data for review.  \n",
      "   - **Contextual Example**: Online forms in e-commerce use Data Validation Rules to prevent submission of incomplete customer information.\n",
      "\n",
      "8. **Data Cleansing**  \n",
      "   - **Definition**: The process of identifying and correcting or removing inaccurate, incomplete, or irrelevant parts of data to improve its quality and usability.  \n",
      "   - **Contextual Example**: Customer databases undergo cleansing to standardize address formats and remove duplicates before analysis.\n",
      "\n",
      "9. **Metadata Management Policy**  \n",
      "   - **Definition**: A policy outlining the processes for creating, maintaining, and disposing of metadata within an organization.  \n",
      "   - **Contextual Example**: Government agencies use Metadata Management Policies to ensure consistent handling of public data across departments.\n",
      "\n",
      "10. **Data Integrity Constraints**  \n",
      "    - **Definition**: Rules enforced during data entry or processing to maintain the accuracy and consistency of data, often implemented through databases or metadata systems.  \n",
      "    - **Contextual Example**: Online banking platforms enforce Data Integrity Constraints to prevent unauthorized transactions and ensure user account security.\n",
      "\n",
      "Each concept is defined with examples that illustrate its practical application in various organizational contexts, providing a clear understanding of their roles and significance in data governance and management.\u001b[00m\n",
      "\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CrewOutput(raw=\"1. **Data Governance Framework**  \\n   - **Definition**: A structured approach to managing data policies, standards, and processes within an organization to ensure compliance, consistency, and quality of data assets.  \\n   - **Contextual Example**: Organizations like XYZ utilize Data Governance Frameworks to implement data quality policies that prevent errors and ensure data usability across departments.\\n\\n2. **Data Quality Scorecard**  \\n   - **Definition**: A tool used to monitor and evaluate the quality of data within an organization, often presented as a score or rating based on predefined metrics.  \\n   - **Contextual Example**: Companies use Data Quality Scorecards to track metrics like completeness, accuracy, and consistency, helping them identify areas for improvement.\\n\\n3. **Metadata Schema**  \\n   - **Definition**: A comprehensive document describing the structure of metadata within an organization, detailing data elements, relationships, and access controls.  \\n   - **Contextual Example**: In healthcare, Metadata Schemas are used to manage patient records, ensuring that information is standardized and easily accessible by different systems.\\n\\n4. **Data Warehouse Schema Design**  \\n   - **Definition**: The process of designing the structure of a Data Warehouse, including tables, columns, relationships, and constraints to organize data effectively.  \\n   - **Contextual Example**: A retail company might design its Data Warehouse Schema to store sales transactions, inventory levels, and customer demographics for efficient reporting.\\n\\n5. **Extract, Transform, Load (ETL) Process**  \\n   - **Definition**: A process used in data warehousing to extract data from various sources, transform it into a usable format, and load it into the target system.  \\n   - **Contextual Example**: An e-commerce platform uses ETL processes to aggregate sales data from different databases, clean the data, and load it into its Data Warehouse for analytics.\\n\\n6. **Data Mart**  \\n   - **Definition**: A subset of a Data Warehouse that focuses on specific business functions or departments, providing tailored data for operational needs.  \\n   - **Contextual Example**: A university's Academic Data Mart aggregates student records, course information, and research data to support academic reporting and planning.\\n\\n7. **Data Validation Rules**  \\n   - **Definition**: Predefined rules used to ensure the integrity of data during entry or processing, flagging invalid or incomplete data for review.  \\n   - **Contextual Example**: Online forms in e-commerce use Data Validation Rules to prevent submission of incomplete customer information.\\n\\n8. **Data Cleansing**  \\n   - **Definition**: The process of identifying and correcting or removing inaccurate, incomplete, or irrelevant parts of data to improve its quality and usability.  \\n   - **Contextual Example**: Customer databases undergo cleansing to standardize address formats and remove duplicates before analysis.\\n\\n9. **Metadata Management Policy**  \\n   - **Definition**: A policy outlining the processes for creating, maintaining, and disposing of metadata within an organization.  \\n   - **Contextual Example**: Government agencies use Metadata Management Policies to ensure consistent handling of public data across departments.\\n\\n10. **Data Integrity Constraints**  \\n    - **Definition**: Rules enforced during data entry or processing to maintain the accuracy and consistency of data, often implemented through databases or metadata systems.  \\n    - **Contextual Example**: Online banking platforms enforce Data Integrity Constraints to prevent unauthorized transactions and ensure user account security.\\n\\nEach concept is defined with examples that illustrate its practical application in various organizational contexts, providing a clear understanding of their roles and significance in data governance and management.\", pydantic=None, json_dict=None, tasks_output=[TaskOutput(description=\"Identify and define all key concepts presented in the document.For each concept, provide a detailed definition along with contextual examples or use cases that illustrate its application.Present each concept in the format: 'Concept Name: Detailed Definition with Contextual Examples'.\", name=None, expected_output='A list of key concepts, with each concept accompanied by a detailed definition and contextual examples or use cases.', summary='Identify and define all key concepts presented in the document.For...', raw=\"1. **Data Governance Framework**  \\n   - **Definition**: A structured approach to managing data policies, standards, and processes within an organization to ensure compliance, consistency, and quality of data assets.  \\n   - **Contextual Example**: Organizations like XYZ utilize Data Governance Frameworks to implement data quality policies that prevent errors and ensure data usability across departments.\\n\\n2. **Data Quality Scorecard**  \\n   - **Definition**: A tool used to monitor and evaluate the quality of data within an organization, often presented as a score or rating based on predefined metrics.  \\n   - **Contextual Example**: Companies use Data Quality Scorecards to track metrics like completeness, accuracy, and consistency, helping them identify areas for improvement.\\n\\n3. **Metadata Schema**  \\n   - **Definition**: A comprehensive document describing the structure of metadata within an organization, detailing data elements, relationships, and access controls.  \\n   - **Contextual Example**: In healthcare, Metadata Schemas are used to manage patient records, ensuring that information is standardized and easily accessible by different systems.\\n\\n4. **Data Warehouse Schema Design**  \\n   - **Definition**: The process of designing the structure of a Data Warehouse, including tables, columns, relationships, and constraints to organize data effectively.  \\n   - **Contextual Example**: A retail company might design its Data Warehouse Schema to store sales transactions, inventory levels, and customer demographics for efficient reporting.\\n\\n5. **Extract, Transform, Load (ETL) Process**  \\n   - **Definition**: A process used in data warehousing to extract data from various sources, transform it into a usable format, and load it into the target system.  \\n   - **Contextual Example**: An e-commerce platform uses ETL processes to aggregate sales data from different databases, clean the data, and load it into its Data Warehouse for analytics.\\n\\n6. **Data Mart**  \\n   - **Definition**: A subset of a Data Warehouse that focuses on specific business functions or departments, providing tailored data for operational needs.  \\n   - **Contextual Example**: A university's Academic Data Mart aggregates student records, course information, and research data to support academic reporting and planning.\\n\\n7. **Data Validation Rules**  \\n   - **Definition**: Predefined rules used to ensure the integrity of data during entry or processing, flagging invalid or incomplete data for review.  \\n   - **Contextual Example**: Online forms in e-commerce use Data Validation Rules to prevent submission of incomplete customer information.\\n\\n8. **Data Cleansing**  \\n   - **Definition**: The process of identifying and correcting or removing inaccurate, incomplete, or irrelevant parts of data to improve its quality and usability.  \\n   - **Contextual Example**: Customer databases undergo cleansing to standardize address formats and remove duplicates before analysis.\\n\\n9. **Metadata Management Policy**  \\n   - **Definition**: A policy outlining the processes for creating, maintaining, and disposing of metadata within an organization.  \\n   - **Contextual Example**: Government agencies use Metadata Management Policies to ensure consistent handling of public data across departments.\\n\\n10. **Data Integrity Constraints**  \\n    - **Definition**: Rules enforced during data entry or processing to maintain the accuracy and consistency of data, often implemented through databases or metadata systems.  \\n    - **Contextual Example**: Online banking platforms enforce Data Integrity Constraints to prevent unauthorized transactions and ensure user account security.\\n\\nEach concept is defined with examples that illustrate its practical application in various organizational contexts, providing a clear understanding of their roles and significance in data governance and management.\", pydantic=None, json_dict=None, agent='Concept Definition Agent', output_format=<OutputFormat.RAW: 'raw'>)], token_usage=UsageMetrics(total_tokens=0, prompt_tokens=0, cached_prompt_tokens=0, completion_tokens=0, successful_requests=0))"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "definition_extract_crew.kickoff(inputs=text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "analysis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
